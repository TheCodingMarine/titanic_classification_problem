{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import multiprocessing\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "y_train = train['Survived']\n",
    "\n",
    "train.drop(['Survived', 'Cabin', 'Ticket', 'Name'], axis=1, inplace=True)\n",
    "test.drop(['Cabin', 'Ticket', 'Name'], axis=1, inplace=True)\n",
    "\n",
    "train.set_index('PassengerId', inplace=True)\n",
    "test.set_index('PassengerId', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female' 'male']\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "genders = train['Sex'].unique()\n",
    "pclasses = train['Pclass'].unique()\n",
    "\n",
    "genders.sort()\n",
    "pclasses.sort()\n",
    "\n",
    "print(genders)\n",
    "print(pclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to separate passengers by 'Sex' and 'Pclass'\n",
    "def separate_passengers_by_gender_and_class(df, genders, pclasses):\n",
    "    frames = []\n",
    "    for gender in genders:\n",
    "        for pclass in pclasses:\n",
    "            frame = df[(df['Sex'] == gender) & (df['Pclass'] == pclass)].copy()\n",
    "            frames.append(frame)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_class_women, second_class_women, third_class_women, first_class_men, second_class_men, third_class_men = separate_passengers_by_gender_and_class(train, genders, pclasses)\n",
    "frames_list = [first_class_men, second_class_men, third_class_men, first_class_women, second_class_women, third_class_women]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40.0, 30.0, 25.0, 35.0, 28.0, 21.5]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List comprehension to calculate median age for each dataframe in list of dataframes\n",
    "frames_list = [first_class_men, second_class_men, third_class_men, first_class_women, second_class_women, third_class_women]\n",
    "median_ages = [df['Age'].median() for df in frames_list]\n",
    "median_ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace impute missing ages with median ages for each sex and class pair\n",
    "for i in range (0, len(frames_list)):\n",
    "    frames_list[i]['Age'].fillna(median_ages[i], inplace=True)\n",
    "\n",
    "#Stitch together the dataframes\n",
    "train_data = pd.concat(frames_list)\n",
    "\n",
    "#Sort the dataframe by PassengerId\n",
    "train_data.sort_values(by='PassengerId', inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 891 entries, 1 to 891\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    891 non-null    int64  \n",
      " 1   Sex       891 non-null    object \n",
      " 2   Age       891 non-null    float64\n",
      " 3   SibSp     891 non-null    int64  \n",
      " 4   Parch     891 non-null    int64  \n",
      " 5   Fare      891 non-null    float64\n",
      " 6   Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 55.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of attributes for preprocessing pipeline\n",
    "num_attribs = ['SibSp', 'Parch', 'Fare', 'Age']\n",
    "cat_attribs = ['Pclass', 'Embarked', 'Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create pipeline for preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"std_scaler\", StandardScaler()),   \n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"one_hot_encoder\", OneHotEncoder()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.43279337, -0.47367361, -0.50244517, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.43279337, -0.47367361,  0.78684529, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.4745452 , -0.47367361, -0.48885426, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.43279337,  2.00893337, -0.17626324, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.4745452 , -0.47367361, -0.04438104, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.4745452 , -0.47367361, -0.49237783, ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create preprocessing pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocess_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", cat_pipeline, cat_attribs),\n",
    "])\n",
    "\n",
    "X_train = preprocess_pipeline.fit_transform(train_data[num_attribs + cat_attribs])\n",
    "\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.to_pickle(X_train, '../data/X_train_v2.pkl')\n",
    "pd.to_pickle(y_train, '../data/y_train_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = preprocess_pipeline.transform(test[num_attribs + cat_attribs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(X_test, '../data/X_test_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
