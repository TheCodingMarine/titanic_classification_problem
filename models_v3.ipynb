{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import multiprocessing\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "y_train = train_data['Survived']\n",
    "train_data.drop(['Survived', 'Cabin', 'Ticket', 'Name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset index to PassengerId\n",
    "train_data.set_index('PassengerId', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of attributes for preprocessing pipeline\n",
    "num_attribs = ['Parch', 'Age', 'SibSp', 'Fare']\n",
    "cat_attribs = ['Pclass', 'Embarked', 'Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create pipeline for preprocessing\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"std_scaler\", StandardScaler()),   \n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"one_hot_encoder\", OneHotEncoder()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/04 16:04:52 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2023/07/04 16:04:52 WARNING mlflow.sklearn: Failed to infer model signature: the trained model does not specify a `predict` function, which is required in order to infer the signature\n",
      "2023/07/04 16:04:52 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/04 16:04:54 WARNING mlflow.data.pandas_dataset: Failed to infer schema for Pandas dataset. Exception: Unable to map 'object' type to MLflow DataType. object can be mapped iff all values have identical data type which is one of (string, (bytes or byterray),  int, float).\n",
      "2023/07/04 16:04:54 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2023/07/04 16:04:54 WARNING mlflow.sklearn: Failed to infer model signature: the trained model does not specify a `predict` function, which is required in order to infer the signature\n",
      "2023/07/04 16:04:54 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2023/07/04 16:04:56 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 4f62c32ba9ea415095a06b7723ae4f6a. Failed operations: [MlflowException(\"Changing param values is not allowed. Param with key=\\'steps\\' was already logged with value=\\'[(\\'imputer\\', SimpleImputer(strategy=\\'median\\')), (\\'std_scaler\\', StandardScaler())]\\' for run ID=\\'4f62c32ba9ea415095a06b7723ae4f6a\\'. Attempted logging new value \\'[(\\'one_hot_encoder\\', OneHotEncoder()), (\\'imputer\\', SimpleImputer(strategy=\\'median\\'))]\\'.\")]')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.47367361, -0.56573646,  0.43279337, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.47367361,  0.66386103,  0.43279337, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.47367361, -0.25833709, -0.4745452 , ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 2.00893337, -0.1046374 ,  0.43279337, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.47367361, -0.25833709, -0.4745452 , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.47367361,  0.20276197, -0.4745452 , ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create preprocessing pipeline\n",
    "preprocess_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", cat_pipeline, cat_attribs),\n",
    "])\n",
    "\n",
    "X_train = preprocess_pipeline.fit_transform(train_data[num_attribs + cat_attribs])\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_pickle(X_train, 'data/X_train.pkl')\n",
    "# pd.to_pickle(y_train, 'data/y_train.pkl')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import cross validation and optimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score \n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#Import models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import warnings\n",
    "import warnings\n",
    "\n",
    "#Ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment tracking\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Begin logging\n",
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/ty/code/data_science/analysis/Titanic-Analysis/mlruns/431820994769440421', creation_time=1688500931603, experiment_id='431820994769440421', last_update_time=1688500931603, lifecycle_stage='active', name='Random Forest Classifier', tags={}>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set Experiment name\n",
    "mlflow.set_experiment('Random Forest Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/04 16:07:31 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2023/07/04 16:07:34 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 4f62c32ba9ea415095a06b7723ae4f6a. Failed operations: [MlflowException(\"Changing param values is not allowed. Param with key=\\'verbose\\' was already logged with value=\\'False\\' for run ID=\\'4f62c32ba9ea415095a06b7723ae4f6a\\'. Attempted logging new value \\'0\\'.\")]')]\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tag('Random Forest Classifier', 'Random Forest Classifier')\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_clf.predict(X_train)\n",
    "\n",
    "\n",
    "#Set run name\n",
    "mlflow.set_tag('run_1', 'RandomForestClassifier')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Gradient Boosting Classifier\n",
    "# gb_clf = GradientBoostingClassifier()\n",
    "\n",
    "# #Fit model\n",
    "# gb_clf.fit(X_train, y_train)\n",
    "\n",
    "# #Predict on training set\n",
    "# y_pred = gb_clf.predict(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Make SGD Classifier\n",
    "# sgd_clf = SGDClassifier()\n",
    "\n",
    "# #Fit model\n",
    "# sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "# #Predict on training set\n",
    "# y_pred = sgd_clf.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
